user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # Performance settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size {{ nginx_config.client_max_body_size | default('10m') }};

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate auth;
    gzip_types text/plain text/css text/xml application/json application/javascript application/xml+rss application/atom+xml image/svg+xml;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=health:10m rate=100r/s;

    # Upstream configuration for Wazuh services
    upstream wazuh_manager {
        least_conn;
        server wazuh-manager:55000 max_fails=3 fail_timeout=30s;
        keepalive {{ nginx_config.upstream_keepalive | default('32') }};
    }

    upstream wazuh_dashboard {
        least_conn;
        server wazuh-dashboard:5601 max_fails=3 fail_timeout=30s;
        keepalive {{ nginx_config.upstream_keepalive | default('32') }};
    }

    upstream wazuh_indexer {
        least_conn;
        server wazuh-indexer:9200 max_fails=3 fail_timeout=30s;
        keepalive {{ nginx_config.upstream_keepalive | default('32') }};
    }

    # Health check server
    server {
        listen 80 default_server;
        listen [::]:80 default_server;
        server_name _;

        # Health check endpoint
        location /health {
            limit_req zone=health burst=20 nodelay;
            access_log off;
            
            add_header Content-Type application/json;
            return 200 '{
                "status": "success",
                "message": "Wazuh Stack is healthy",
                "timestamp": "$time_iso8601",
                "services": {
                    "nginx": "running",
                    "manager": "proxied",
                    "dashboard": "proxied", 
                    "indexer": "proxied"
                },
                "version": "1.0.0",
                "environment": "production"
            }';
        }

        # API health check with service validation
        location /health/detailed {
            limit_req zone=health burst=10 nodelay;
            
            content_by_lua_block {
                local http = require "resty.http"
                local json = require "cjson"
                
                local function check_service(url, name)
                    local httpc = http.new()
                    httpc:set_timeout(5000)
                    
                    local res, err = httpc:request_uri(url, {
                        method = "GET",
                        headers = { ["User-Agent"] = "nginx-health-check" }
                    })
                    
                    if res and res.status == 200 then
                        return { status = "healthy", response_time = "< 5s" }
                    else
                        return { status = "unhealthy", error = err or "timeout" }
                    end
                end
                
                local services = {
                    manager = check_service("http://wazuh-manager:55000", "manager"),
                    dashboard = check_service("http://wazuh-dashboard:5601", "dashboard"),
                    indexer = check_service("http://wazuh-indexer:9200", "indexer")
                }
                
                local overall_status = "healthy"
                for _, service in pairs(services) do
                    if service.status ~= "healthy" then
                        overall_status = "degraded"
                        break
                    end
                end
                
                local response = {
                    status = overall_status,
                    message = "Detailed health check completed",
                    timestamp = ngx.http_time(ngx.time()),
                    services = services,
                    load_balancer = {
                        status = "running",
                        upstreams_active = true
                    }
                }
                
                ngx.header.content_type = "application/json"
                ngx.say(json.encode(response))
            }
        }

        # Simple status endpoint
        location /status {
            limit_req zone=health burst=50 nodelay;
            access_log off;
            
            add_header Content-Type text/plain;
            return 200 "OK";
        }

        # Metrics endpoint (Prometheus format)
        location /metrics {
            limit_req zone=api burst=5 nodelay;
            
            content_by_lua_block {
                ngx.header.content_type = "text/plain"
                ngx.say("# HELP nginx_connections_active Active connections")
                ngx.say("# TYPE nginx_connections_active gauge")
                ngx.say("nginx_connections_active ", ngx.var.connections_active)
                
                ngx.say("# HELP nginx_connections_reading Reading connections")
                ngx.say("# TYPE nginx_connections_reading gauge")
                ngx.say("nginx_connections_reading ", ngx.var.connections_reading)
                
                ngx.say("# HELP nginx_connections_writing Writing connections")
                ngx.say("# TYPE nginx_connections_writing gauge")
                ngx.say("nginx_connections_writing ", ngx.var.connections_writing)
                
                ngx.say("# HELP nginx_connections_waiting Waiting connections")
                ngx.say("# TYPE nginx_connections_waiting gauge")
                ngx.say("nginx_connections_waiting ", ngx.var.connections_waiting)
            }
        }

        # Redirect root to dashboard
        location / {
            return 301 /dashboard/;
        }

        # Proxy to Wazuh Dashboard
        location /dashboard/ {
            limit_req zone=api burst=10 nodelay;
            
            proxy_pass http://wazuh_dashboard/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            proxy_connect_timeout {{ nginx_config.proxy_connect_timeout | default('75s') }};
            proxy_send_timeout {{ nginx_config.proxy_read_timeout | default('300s') }};
            proxy_read_timeout {{ nginx_config.proxy_read_timeout | default('300s') }};
            
            proxy_buffering off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Proxy to Wazuh API
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://wazuh_manager/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            proxy_connect_timeout {{ nginx_config.proxy_connect_timeout | default('75s') }};
            proxy_send_timeout {{ nginx_config.proxy_read_timeout | default('300s') }};
            proxy_read_timeout {{ nginx_config.proxy_read_timeout | default('300s') }};
            
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Proxy to Wazuh Indexer
        location /indexer/ {
            limit_req zone=api burst=10 nodelay;
            
            rewrite ^/indexer/(.*) /$1 break;
            proxy_pass http://wazuh_indexer;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            proxy_connect_timeout {{ nginx_config.proxy_connect_timeout | default('75s') }};
            proxy_send_timeout {{ nginx_config.proxy_read_timeout | default('300s') }};
            proxy_read_timeout {{ nginx_config.proxy_read_timeout | default('300s') }};
            
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Error pages
        error_page 404 /404.json;
        location = /404.json {
            internal;
            add_header Content-Type application/json;
            return 404 '{"error": "Not Found", "status": 404, "message": "The requested resource was not found"}';
        }

        error_page 500 502 503 504 /50x.json;
        location = /50x.json {
            internal;
            add_header Content-Type application/json;
            return 500 '{"error": "Internal Server Error", "status": 500, "message": "An internal server error occurred"}';
        }
    }

    # HTTPS server (optional - for SSL termination)
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name _;

        # SSL configuration (you can add your certificates here)
        ssl_certificate /etc/nginx/ssl/nginx.crt;
        ssl_certificate_key /etc/nginx/ssl/nginx.key;
        ssl_session_cache shared:SSL:1m;
        ssl_session_timeout 5m;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;

        # Same locations as HTTP server but with SSL
        location /health {
            limit_req zone=health burst=20 nodelay;
            access_log off;
            
            add_header Content-Type application/json;
            return 200 '{
                "status": "success",
                "message": "Wazuh Stack is healthy (SSL)",
                "timestamp": "$time_iso8601",
                "services": {
                    "nginx": "running",
                    "manager": "proxied",
                    "dashboard": "proxied",
                    "indexer": "proxied"
                },
                "ssl": true,
                "version": "1.0.0",
                "environment": "production"
            }';
        }

        location / {
            return 301 /dashboard/;
        }

        # Include other proxy locations...
        include /etc/nginx/conf.d/proxy_locations.conf;
    }
}
